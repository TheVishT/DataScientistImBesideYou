{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9899ab-fef7-440b-b21e-d16a7b492327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d70bcb8-5697-4e48-a61f-aa5c472cd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "emotion_df=pd.read_csv(\"emotion_data/1/emotion.csv\") # Loading emotion score of first student\n",
    "gaze_df=pd.read_csv(\"emotion_data/1/gaze.csv\") # Loading gaze score of first student\n",
    "transcript_df=pd.read_csv(\"transcript_data/1.csv\") # Loading transcript score of first student\n",
    "gaze_df=gaze_df.drop(gaze_df.index[-1]) # Due to one row difference between emotion and gaze for 1st student and to keep unniformity\n",
    "lengths1=[len(emotion_df.index)] # To keep track of number of rows of each student's emotion and gaze \n",
    "lengths2=[len(transcript_df.index)] # To keep track of number of rows of each student for transcript score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7248d08f-3959-4006-a309-968d979cadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,11):\n",
    "    df1=pd.read_csv(\"emotion_data/\"+str(i)+\"/emotion.csv\")\n",
    "    df2=pd.read_csv(\"emotion_data/\"+str(i)+\"/gaze.csv\")\n",
    "    df3=pd.read_csv(\"transcript_data/\"+str(i)+\".csv\")\n",
    "    # Merging the dataframes\n",
    "    emotion_df=pd.merge(emotion_df,df1,how='outer') \n",
    "    gaze_df=pd.merge(gaze_df,df2,how='outer')\n",
    "    transcript_df=pd.merge(transcript_df,df3,how='outer')\n",
    "    lengths1.append(len(df1.index)) # Storing the number of rows of each student's emotion and gaze\n",
    "    lengths2.append(len(df3.index)) # Storing the number of rows of each student's transcript score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0587bdac-246e-4732-9e33-23213b880837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unwanted and redundant columns\n",
    "emotion_df=emotion_df.drop(['movie_id','image_seq','dominant_emotion'],axis=1) \n",
    "gaze_df=gaze_df.drop(['movie_id','image_seq','blink','eye_offset'],axis=1)\n",
    "transcript_df=transcript_df.iloc[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5bac61-af7e-47a8-85ee-ba4cf41d48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1_df=pd.concat([emotion_df,gaze_df],axis=1) # result1 has the concatenated dataframe of emotion_df and gaze_df\n",
    "result2_df=transcript_df #result2 has the dataframe transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc6e447-c134-4172-83a0-579b4dce4900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>gaze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.317350</td>\n",
       "      <td>5.942640e-04</td>\n",
       "      <td>2.879790</td>\n",
       "      <td>1.650350e+00</td>\n",
       "      <td>2.779980</td>\n",
       "      <td>0.600814</td>\n",
       "      <td>87.77110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.225300</td>\n",
       "      <td>2.981640e+00</td>\n",
       "      <td>12.736800</td>\n",
       "      <td>1.523470e+00</td>\n",
       "      <td>1.051320</td>\n",
       "      <td>27.216800</td>\n",
       "      <td>1.26462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.796510</td>\n",
       "      <td>2.946810e-02</td>\n",
       "      <td>2.968160</td>\n",
       "      <td>1.683150e+01</td>\n",
       "      <td>39.884600</td>\n",
       "      <td>0.279335</td>\n",
       "      <td>31.21050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.453030</td>\n",
       "      <td>1.067780e-01</td>\n",
       "      <td>1.553080</td>\n",
       "      <td>2.093010e+01</td>\n",
       "      <td>3.503870</td>\n",
       "      <td>0.909426</td>\n",
       "      <td>63.54370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.000200</td>\n",
       "      <td>4.152410e-06</td>\n",
       "      <td>0.162231</td>\n",
       "      <td>5.583580e+00</td>\n",
       "      <td>0.197026</td>\n",
       "      <td>12.807600</td>\n",
       "      <td>25.24940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>21.623500</td>\n",
       "      <td>3.223740e-01</td>\n",
       "      <td>55.701200</td>\n",
       "      <td>1.837300e+00</td>\n",
       "      <td>14.471100</td>\n",
       "      <td>2.007100</td>\n",
       "      <td>4.03747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.483833</td>\n",
       "      <td>8.153230e-05</td>\n",
       "      <td>83.415300</td>\n",
       "      <td>2.197600e+00</td>\n",
       "      <td>12.474100</td>\n",
       "      <td>0.059187</td>\n",
       "      <td>1.36993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.175224</td>\n",
       "      <td>4.728190e-10</td>\n",
       "      <td>13.272400</td>\n",
       "      <td>1.959540e-09</td>\n",
       "      <td>63.701500</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>22.85090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.326095</td>\n",
       "      <td>2.007640e-05</td>\n",
       "      <td>1.177400</td>\n",
       "      <td>3.822260e-02</td>\n",
       "      <td>33.006200</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>65.44100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.041253</td>\n",
       "      <td>4.232110e-08</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>1.281550e-02</td>\n",
       "      <td>0.843036</td>\n",
       "      <td>0.035985</td>\n",
       "      <td>99.06120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>747 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         angry       disgust       fear         happy        sad   surprise  \\\n",
       "0     4.317350  5.942640e-04   2.879790  1.650350e+00   2.779980   0.600814   \n",
       "1    53.225300  2.981640e+00  12.736800  1.523470e+00   1.051320  27.216800   \n",
       "2     8.796510  2.946810e-02   2.968160  1.683150e+01  39.884600   0.279335   \n",
       "3     9.453030  1.067780e-01   1.553080  2.093010e+01   3.503870   0.909426   \n",
       "4    56.000200  4.152410e-06   0.162231  5.583580e+00   0.197026  12.807600   \n",
       "..         ...           ...        ...           ...        ...        ...   \n",
       "742  21.623500  3.223740e-01  55.701200  1.837300e+00  14.471100   2.007100   \n",
       "743   0.483833  8.153230e-05  83.415300  2.197600e+00  12.474100   0.059187   \n",
       "744   0.175224  4.728190e-10  13.272400  1.959540e-09  63.701500   0.000002   \n",
       "745   0.326095  2.007640e-05   1.177400  3.822260e-02  33.006200   0.011101   \n",
       "746   0.041253  4.232110e-08   0.005674  1.281550e-02   0.843036   0.035985   \n",
       "\n",
       "      neutral  gaze  \n",
       "0    87.77110     1  \n",
       "1     1.26462     1  \n",
       "2    31.21050     1  \n",
       "3    63.54370     1  \n",
       "4    25.24940     1  \n",
       "..        ...   ...  \n",
       "742   4.03747     0  \n",
       "743   1.36993     1  \n",
       "744  22.85090     1  \n",
       "745  65.44100     1  \n",
       "746  99.06120     1  \n",
       "\n",
       "[747 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3920000-8f9d-448e-9f30-17d466a6369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_speech_prob</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>confident</th>\n",
       "      <th>hesitant</th>\n",
       "      <th>concise</th>\n",
       "      <th>enthusiastic</th>\n",
       "      <th>speech_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.580265</td>\n",
       "      <td>0.152281</td>\n",
       "      <td>0.267454</td>\n",
       "      <td>0.846701</td>\n",
       "      <td>0.845698</td>\n",
       "      <td>0.635805</td>\n",
       "      <td>0.647783</td>\n",
       "      <td>2.517986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.550327</td>\n",
       "      <td>0.189263</td>\n",
       "      <td>0.260410</td>\n",
       "      <td>0.679283</td>\n",
       "      <td>0.733701</td>\n",
       "      <td>0.544145</td>\n",
       "      <td>0.417390</td>\n",
       "      <td>3.217822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>0.248990</td>\n",
       "      <td>0.902729</td>\n",
       "      <td>0.834620</td>\n",
       "      <td>0.715861</td>\n",
       "      <td>0.700062</td>\n",
       "      <td>2.868852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.441894</td>\n",
       "      <td>0.399186</td>\n",
       "      <td>0.158919</td>\n",
       "      <td>0.774308</td>\n",
       "      <td>0.813044</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>0.279916</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.236254</td>\n",
       "      <td>0.532010</td>\n",
       "      <td>0.231735</td>\n",
       "      <td>0.286049</td>\n",
       "      <td>0.561375</td>\n",
       "      <td>0.334381</td>\n",
       "      <td>0.197305</td>\n",
       "      <td>3.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.737435</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.199264</td>\n",
       "      <td>0.821343</td>\n",
       "      <td>0.204142</td>\n",
       "      <td>0.422417</td>\n",
       "      <td>0.254029</td>\n",
       "      <td>3.169014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.594038</td>\n",
       "      <td>0.206492</td>\n",
       "      <td>0.199470</td>\n",
       "      <td>0.455449</td>\n",
       "      <td>0.631635</td>\n",
       "      <td>0.221028</td>\n",
       "      <td>0.127612</td>\n",
       "      <td>2.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.587039</td>\n",
       "      <td>0.207191</td>\n",
       "      <td>0.205771</td>\n",
       "      <td>0.127398</td>\n",
       "      <td>0.436416</td>\n",
       "      <td>0.020206</td>\n",
       "      <td>0.275292</td>\n",
       "      <td>2.866242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.542674</td>\n",
       "      <td>0.259974</td>\n",
       "      <td>0.197352</td>\n",
       "      <td>0.539320</td>\n",
       "      <td>0.450221</td>\n",
       "      <td>0.284381</td>\n",
       "      <td>0.104140</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.963019</td>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.023242</td>\n",
       "      <td>0.807010</td>\n",
       "      <td>0.303308</td>\n",
       "      <td>0.646336</td>\n",
       "      <td>0.479207</td>\n",
       "      <td>3.409091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no_speech_prob  positive  negative   neutral  confident  hesitant  \\\n",
       "0          0.635880  0.580265  0.152281  0.267454   0.846701  0.845698   \n",
       "1          0.635880  0.550327  0.189263  0.260410   0.679283  0.733701   \n",
       "2          0.635880  0.639860  0.111150  0.248990   0.902729  0.834620   \n",
       "3          0.635880  0.441894  0.399186  0.158919   0.774308  0.813044   \n",
       "4          0.635880  0.236254  0.532010  0.231735   0.286049  0.561375   \n",
       "..              ...       ...       ...       ...        ...       ...   \n",
       "169        0.036832  0.737435  0.063301  0.199264   0.821343  0.204142   \n",
       "170        0.036832  0.594038  0.206492  0.199470   0.455449  0.631635   \n",
       "171        0.036832  0.587039  0.207191  0.205771   0.127398  0.436416   \n",
       "172        0.101272  0.542674  0.259974  0.197352   0.539320  0.450221   \n",
       "173        0.101272  0.963019  0.013739  0.023242   0.807010  0.303308   \n",
       "\n",
       "      concise  enthusiastic  speech_speed  \n",
       "0    0.635805      0.647783      2.517986  \n",
       "1    0.544145      0.417390      3.217822  \n",
       "2    0.715861      0.700062      2.868852  \n",
       "3    0.522462      0.279916      3.750000  \n",
       "4    0.334381      0.197305      3.541667  \n",
       "..        ...           ...           ...  \n",
       "169  0.422417      0.254029      3.169014  \n",
       "170  0.221028      0.127612      2.884615  \n",
       "171  0.020206      0.275292      2.866242  \n",
       "172  0.284381      0.104140      2.571429  \n",
       "173  0.646336      0.479207      3.409091  \n",
       "\n",
       "[174 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdca244e-a9df-456c-82e9-d97c01284284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_numpy convert a dataframe to a numpy array\n",
    "result1=result1_df.to_numpy()\n",
    "result2=result2_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e1e4bc-25df-4e9c-a5e0-6583c4e0cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # This is required for Min-Max Scaling\n",
    " \n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(result1)\n",
    "scaled_result1=model.transform(result1) # This is the scaled result1\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(result2)\n",
    "scaled_result2=model.transform(result2)  # This is the scaled result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c861d9-ae30-4c68-9bab-a9935f5f0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will have 2 clusters, 1-student should be recruited and 0-student should not be recruited\n",
    "# For sake of uniformity, if there is a combination of desirable emotion and gaze, or ,transcript it will always belong to cluster 1\n",
    "# Ideal case arrays, to make sure ideal combinations of emotions, gaze and transcript always in cluster 1\n",
    "ideal1 = [0,0,0,1,0,0.5,1,1] # Array with ideal values of emotion and gaze\n",
    "ideal2 = [0,1,0,1,1,0,1,1,0.5] # Array with ideal values of transcript scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f2c48f-db3b-443a-ab51-e29edd6767d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score # To analyse the perfomance of the clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b866e4b-61e1-4fe8-b533-eaf460390f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79c125fb-c72e-42fd-bff9-926df2e77213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_state has been initialised to 0 so that centroids chosen remain the same everytime the code is run\n",
    "# n_init is the number of times the algorithm will be run with different initialisations and choose the one with lowest inertia\n",
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\")\n",
    "kmeans.fit(scaled_result1) # Computes K-Means Clustering for scaled_result1\n",
    "kmeans.predict([ideal1]) # To check if ideal case is giving 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fccb7ed-4a8d-406d-9b90-ed5e89cb2245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3563218390804598,\n",
       " 0.28735632183908044,\n",
       " 0.31,\n",
       " 0.9696969696969697,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.11494252873563218,\n",
       " 0.7311827956989247,\n",
       " 0.32558139534883723,\n",
       " 0.12222222222222222]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=kmeans.labels_ # These are the cluster labels for each row, by K-Means\n",
    "db_index_kmeans_1 = davies_bouldin_score(scaled_result1, predictions) # Stores value of DB Index when using K-Means for scaled_result1\n",
    "ans1_kmeans=[] # The final prediction scores of each student using emotion and gaze and K-Means is stored in this list\n",
    "i=0\n",
    "for l in lengths1: # Using lengths1 to help in taking average of all rows that contribute to each student\n",
    "    ans1_kmeans.append(np.average(predictions[i:i+l]))\n",
    "    i+=l\n",
    "ans1_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d319af1-9164-4b4d-8c7a-a2a0a3751010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly doing for scaled_result2\n",
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\")\n",
    "kmeans.fit(scaled_result2)\n",
    "kmeans.predict([ideal2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b924859f-c8f1-4b2c-be25-993714133ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since in this case ideal values are belonging to cluster-0, we need to swap the clusters\n",
    "# This is to make sure that ideal and good values always remain in cluster 1 for uniformity\n",
    "predictions=kmeans.labels_\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "077344eb-1085-4287-8d66-07e2bed1e833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=1-predictions # Simple way to swap the clusters if only 2 clusters are present\n",
    "predictions # Now ideal case will belong to cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a010921-d400-41d4-92b5-ce039177e310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6666666666666666,\n",
       " 0.5263157894736842,\n",
       " 0.35714285714285715,\n",
       " 0.5263157894736842,\n",
       " 0.47058823529411764,\n",
       " 0.4444444444444444,\n",
       " 0.46153846153846156,\n",
       " 0.5625,\n",
       " 0.4444444444444444,\n",
       " 0.35294117647058826]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_kmeans_2 = davies_bouldin_score(scaled_result2, predictions) # DB Index when using K-Means for scaled_result2\n",
    "ans2_kmeans=[] # The final prediction scores of each student using transcript scores and K-Means is stored in this list\n",
    "i=0\n",
    "for l in lengths2: # Using lengths2 to help in taking average of all rows that contribute to each student\n",
    "    ans2_kmeans.append(np.average(predictions[i:i+l]))\n",
    "    i+=l\n",
    "ans2_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "244bb3f8-17d2-413e-8d83-468235648e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Misture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb940c23-2c9f-4dc4-9c72-c3b3512e1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38cd2278-cb1d-4d38-a320-32f56eafcf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_components tells the algorithm how many clusters to make\n",
    "gaussian_model = GaussianMixture(n_components=2)\n",
    "gaussian_model.fit(scaled_result1) # train the data\n",
    "gaussian_result = gaussian_model.predict(scaled_result1) # assign each data point to a cluster\n",
    "gaussian_model.predict([ideal1]) # To check if ideal case is giving 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cdf0f99-2914-49c1-8ff4-873f0001b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6206896551724138,\n",
       " 0.6091954022988506,\n",
       " 0.45,\n",
       " 0.7878787878787878,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.7816091954022989,\n",
       " 0.946236559139785,\n",
       " 0.9651162790697675,\n",
       " 0.7333333333333333]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_gaussian_1 = davies_bouldin_score(scaled_result1, gaussian_result) # DB Index when using GMM for scaled_result1\n",
    "ans1_gaussian=[]  # The final prediction scores of each student using emotion, gaze and GMM is stored in this list\n",
    "i=0\n",
    "for l in lengths1:\n",
    "    ans1_gaussian.append(np.average(gaussian_result[i:i+l]))\n",
    "    i+=l\n",
    "ans1_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f51ff052-6d47-4da8-af59-5480da05a0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly doing for scaled_result2\n",
    "gaussian_model = GaussianMixture(n_components=2)\n",
    "gaussian_model.fit(scaled_result2) # train the data\n",
    "gaussian_result = gaussian_model.predict(scaled_result2) # assign each data point to a cluster\n",
    "gaussian_model.predict([ideal2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46c88635-b919-4dc5-8889-9a5081088632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16666666666666666,\n",
       " 0.3157894736842105,\n",
       " 0.5714285714285714,\n",
       " 0.42105263157894735,\n",
       " 0.47058823529411764,\n",
       " 0.3333333333333333,\n",
       " 0.38461538461538464,\n",
       " 0.5,\n",
       " 0.4444444444444444,\n",
       " 0.5882352941176471]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_gaussian_2 = davies_bouldin_score(scaled_result2, gaussian_result) # DB Index when using GMM for scaled_result2\n",
    "ans2_gaussian=[] # The final prediction scores of each student using transcript score and GMM is stored in this list\n",
    "i=0\n",
    "for l in lengths2:\n",
    "    ans2_gaussian.append(np.average(gaussian_result[i:i+l]))\n",
    "    i+=l\n",
    "ans2_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba20fa6d-454b-4d3c-91b4-2186054f3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fcf05f7-a228-4a48-bf84-e74533a507c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14cf3312-b29a-4433-bfce-961b9250529f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_clusters tells the algorithm how many clusters are there\n",
    "agglomerative_model = AgglomerativeClustering(n_clusters=2)\n",
    "scaled_result1_with_ideal=np.row_stack([ideal1,scaled_result1]) # Including the ideal case to check whcih cluster it belongs\n",
    "agglomerative_result = agglomerative_model.fit_predict(scaled_result1_with_ideal) # Performing prediction \n",
    "agglomerative_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b904b19-f1e0-426a-a7c2-f29204b5c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As ideal case belongs to cluster 0, clusters have to be swapped after prediction\n",
    "agglomerative_result = agglomerative_model.fit_predict(scaled_result1) # Predicting for the scaled_result1\n",
    "agglomerative_result=1-agglomerative_result # Now ideal case will belong to cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bed5d320-bc30-4296-8080-89b171f882ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6206896551724138,\n",
       " 0.6091954022988506,\n",
       " 0.45,\n",
       " 0.7878787878787878,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.7816091954022989,\n",
       " 0.946236559139785,\n",
       " 0.9651162790697675,\n",
       " 0.7333333333333333]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_agglomerative_1 = davies_bouldin_score(scaled_result1, agglomerative_result) # DB Index when using Agglomerative for scaled_result1\n",
    "ans1_agglomerative=[]  # The final prediction scores of each student using emotion, gaze and Agglomerative is stored in this list\n",
    "i=0\n",
    "for l in lengths1:\n",
    "    ans1_agglomerative.append(np.average(agglomerative_result[i:i+l]))\n",
    "    i+=l\n",
    "ans1_agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35e8ba1a-dd33-46c1-9fc4-6f709e1da6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly doing for scaled_result2\n",
    "agglomerative_model = AgglomerativeClustering(n_clusters=2)\n",
    "scaled_result2_with_ideal=np.row_stack([ideal2,scaled_result2]) # Including the ideal case to check whcih cluster it belongs\n",
    "agglomerative_result = agglomerative_model.fit_predict(scaled_result2_with_ideal) # Performing prediction \n",
    "agglomerative_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e58393d-2f34-4108-a590-8e8edf6eee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As ideal case belongs to cluster 0, clusters have to be swapped after prediction\n",
    "agglomerative_result = agglomerative_model.fit_predict(scaled_result2) # Predicting for the scaled_result1\n",
    "agglomerative_result=1-agglomerative_result # Now ideal case will belong to cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b5de8ed-6492-4f6b-8248-28bf0788988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8888888888888888,\n",
       " 0.8947368421052632,\n",
       " 0.6785714285714286,\n",
       " 0.6842105263157895,\n",
       " 0.7058823529411765,\n",
       " 0.8333333333333334,\n",
       " 0.7692307692307693,\n",
       " 0.5625,\n",
       " 0.8888888888888888,\n",
       " 0.7647058823529411]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_agglomerative_2 = davies_bouldin_score(scaled_result2, agglomerative_result)  # DB Index when using Agglomerative for scaled_result2\n",
    "ans2_agglomerative=[] # The final prediction scores of each student using transcript score and Agglomerative is stored in this list\n",
    "i=0\n",
    "for l in lengths2:\n",
    "    ans2_agglomerative.append(np.average(agglomerative_result[i:i+l]))\n",
    "    i+=l\n",
    "ans2_agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c27d1afc-c6ab-47b9-819f-c9d36a0399f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to check which clustering algorithm works best. \n",
    "# The algortihm with the lowest Davies-Bouldin Index is the best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2002b73a-791c-426e-9e39-fd84d5decfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2723514577449737"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_kmeans_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7949eacc-61bd-41ee-a98a-fc7ddee6380f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7255051146526268"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_kmeans_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a331e43-1f8d-457e-aee2-8d47472cba45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1430053187993996"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_gaussian_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97674311-e259-489f-86fa-d800b427a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8186697617003467"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_gaussian_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bbee95a-6d08-4604-9806-ed89a94fe126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1430053187993996"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_agglomerative_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "376515b6-59cd-48b6-8d46-4bc70653e5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5727742568753424"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_index_agglomerative_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1db788bb-79b2-44dc-853c-aed7db5a8f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For both the datasets, agglomerative clustering is having the lowest DB Index\n",
    "# So it is the best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8a9c224-caf9-4fd9-aa65-f70223bfcabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6206896551724138, 0.8888888888888888],\n",
       " [0.6091954022988506, 0.8947368421052632],\n",
       " [0.45, 0.6785714285714286],\n",
       " [0.7878787878787878, 0.6842105263157895],\n",
       " [1.0, 0.7058823529411765],\n",
       " [1.0, 0.8333333333333334],\n",
       " [0.7816091954022989, 0.7692307692307693],\n",
       " [0.946236559139785, 0.5625],\n",
       " [0.9651162790697675, 0.8888888888888888],\n",
       " [0.7333333333333333, 0.7647058823529411]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ans = [[x,y] for x, y in zip(ans1_agglomerative, ans2_agglomerative)] # Stores the final predicted recruitability of all 10 students\n",
    "# First element shows the recruitability of student based on their emotion and gaze\n",
    "# Second element shows the recruitability of student based on their transcript score\n",
    "# If value is closer to 1, then student is more suitable for recruitment\n",
    "final_ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2785c8-3557-4836-b147-b210ff751f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
